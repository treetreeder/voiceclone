import time

import json

import os

import numpy as np

import torch

import soundfile as sf

from qwen_tts import Qwen3TTSModel



# Enable TensorFloat32 for better performance on Ampere+ GPUs

torch.set_float32_matmul_precision('high')



def run_generation(model, text, language, voice_clone_prompt):

    """Run generation with GPU synchronization for accurate timing."""

    torch.cuda.synchronize()

    start = time.perf_counter()



    wavs, sr = model.generate_voice_clone(

        text=text,

        language=language,

        voice_clone_prompt=voice_clone_prompt,

        x_vector_only_mode=True

    )



    torch.cuda.synchronize()

    total_time = time.perf_counter() - start

   

    audio = wavs[0] if wavs else np.array([])

    duration = len(audio) / sr if sr > 0 else 0

    rtf = total_time / duration if duration > 0 else 0



    return {

        "total_time": total_time,

        "audio": audio,

        "sample_rate": sr,

        "audio_duration": duration,

        "rtf": rtf

    }



def main():

    total_start = time.time()

   

    # IMPORTANT: Ensure this matches the path where NestJS is writing files

    # If NestJS writes to a 'shared' folder, change this to that specific path

    base_dir = os.path.dirname(os.path.abspath(__file__))



    print("=" * 60)

    print("üöÄ Qwen3-TTS Worker Ready (RTX 4090)")

    print(f"üìÇ Monitoring Directory: {base_dir}")

    print("=" * 60)



    # Load Model

    model = Qwen3TTSModel.from_pretrained(

        "Qwen/Qwen3-TTS-12Hz-1.7B-Base",

        device_map="cuda:0",

        dtype=torch.bfloat16,

        attn_implementation="flash_attention_2",

    )



    model.enable_streaming_optimizations(

        use_compile=True,

        compile_mode="max-autotune",

    )



    # Warmup - Essential for Torch Compile

    print("\nüî• Initializing Kernels (Warmup)...")

    warmup_sr = 24000

    dummy_prompt = model.create_voice_clone_prompt(

        ref_audio=(np.zeros(warmup_sr), warmup_sr),

        ref_text="warmup"

    )

    run_generation(model, "Warmup generation.", "English", dummy_prompt)

    print("‚úÖ System Ready.")



    counter = 1

    while True:

        choice = input(f"\n[{counter}] Enter JSON number (1-4) or 'EXIT': ").strip()

       

        if choice.upper() == "EXIT":

            print(f"\nShutting down. Total uptime: {time.time() - total_start:.2f}s")

            break

       

        # Build the path to the file generated by NestJS

        json_path = os.path.join(base_dir, f"{choice}.json")

       

        # Check if file exists (Fresh check every loop iteration)

        if not os.path.exists(json_path):

            print(f"‚ùå File not found: {json_path}")

            print(f"üëâ Tip: Ensure NestJS is writing to: {os.path.abspath(base_dir)}")

            continue



        try:

            # Read the file

            with open(json_path, 'r', encoding='utf-8') as f:

                data = json.load(f)

           

            # Extract fields

            ref_audio = data["ref_audio_path"]

            # If NestJS provides a relative path, resolve it relative to the base_dir

            if not os.path.isabs(ref_audio):

                ref_audio = os.path.join(base_dir, ref_audio)



            print(f"üìñ Processing Task {choice} | Lang: {data['language']}")



            # Create prompt and generate

            prompt = model.create_voice_clone_prompt(

                ref_audio=ref_audio,

                ref_text=data["ref_text"]

            )

           

            res = run_generation(model, data["user_text"], data["language"], prompt)



            # Save Output

            out_filename = os.path.join(base_dir, f"output_{choice}.wav")

            sf.write(out_filename, res["audio"], res["sample_rate"])

           

            print(f"‚ú® Success: {out_filename}")

            print(f"üìä Performance: RTF {res['rtf']:.4f} | Time: {res['total_time']:.3f}s")

           

            counter += 1



        except Exception as e:

            print(f"‚ö†Ô∏è Error reading/processing {choice}.json: {e}")



if __name__ == "__main__":

    main()