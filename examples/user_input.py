import time
import numpy as np
import torch
import soundfile as sf
from qwen_tts import Qwen3TTSModel

# Enable TensorFloat32 for better performance on Ampere+ GPUs
torch.set_float32_matmul_precision('high')

def log_time(start, operation):
    elapsed = time.time() - start
    print(f"[{elapsed:.2f}s] {operation}")
    return time.time()

def run_generation(
    model,
    text: str,
    language: str,
    voice_clone_prompt,
    label: str = "generation",
):
    """Run non-streaming generation and return timing stats with GPU sync."""
    torch.cuda.synchronize()
    start = time.perf_counter()

    wavs, sr = model.generate_voice_clone(
        text=text,
        language=language,
        voice_clone_prompt=voice_clone_prompt,
        x_vector_only_mode=True
    )

    torch.cuda.synchronize()
    total_time = time.perf_counter() - start
    
    audio = wavs[0] if wavs else np.array([])
    audio_duration = len(audio) / sr if sr > 0 else 0
    rtf = total_time / audio_duration if audio_duration > 0 else 0

    return {
        "label": label,
        "total_time": total_time,
        "audio": audio,
        "sample_rate": sr,
        "audio_duration": audio_duration,
        "rtf": rtf,
        "text": text
    }

def main():
    total_start = time.time()

    print("=" * 60)
    print("ğŸš€ Initializing Qwen3-TTS on RTX 4090")
    print("=" * 60)

    start = time.time()
    model = Qwen3TTSModel.from_pretrained(
        "Qwen/Qwen3-TTS-12Hz-1.7B-Base",
        device_map="cuda:0",
        dtype=torch.bfloat16,
        attn_implementation="flash_attention_2",
    )
    log_time(start, "Model loaded")

    # Reference audio setup
    ref_audio_path = "voice.wav"
    ref_text = (
        "æˆ‘ä»¬å…šå¿…é¡»åšå®šåœ°ç«™åœ¨æ—¶ä»£æ½®æµçš„å‰å¤´"
        "å›¢ç»“å’Œå¸¦é¢†å…¨å›½å„æ—äººæ°‘ï¼Œå®ç°æ¨è¿›ç°ä»£åŒ–å»ºè®¾ã€å®Œæˆç¥–å›½ç»Ÿä¸€ã€ç»´æŠ¤ä¸–ç•Œå’Œå¹³ä¸ä¿ƒè¿›å…±åŒå‘å±•è¿™ä¸‰å¤§å†å²ä»»åŠ¡ï¼Œ"
        "åœ¨ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰é“è·¯ä¸Šå®ç°ä¸­åæ°‘æ—çš„ä¼Ÿå¤§å¤å…´ã€‚è¿™æ˜¯å†å²å’Œæ—¶ä»£"
    )

    start = time.time()
    voice_clone_prompt = model.create_voice_clone_prompt(
        ref_audio=ref_audio_path,
        ref_text=ref_text,
    )
    log_time(start, "Voice clone prompt created")

    # ============== Setup Optimizations ==============
    print("\nEnabling optimizations (max-autotune)...")
    model.enable_streaming_optimizations(
        decode_window_frames=1200,
        use_compile=True,
        use_cuda_graphs=False,
        compile_mode="max-autotune",
        use_fast_codebook=True,
        compile_codebook_predictor=True,
        compile_talker=True,
    )

    # ============== Warmup Runs ==============
    warmup_texts = ["éšç€æ–°å¹´å°†è‡³ï¼Œå„å¤§ç¤¾äº¤åª’ä½“ä¸Šï¼Œâ€œæœªå©šç¾¤ä½“æ˜¯å¦è¦ç»™å‹å²é’±â€çš„è¯é¢˜å†æ¬¡â€œä¸Šäº†æ¡Œâ€ã€‚éšç€ç¤¾ä¼šå…³ç³»æ—¥è¶‹å¤šå…ƒï¼Œå‹å²é’±çš„å‘ˆç°å½¢å¼ä¹Ÿéšä¹‹å‘ç”Ÿå˜åŒ–ã€‚ä½†å½¢å¼å˜åŒ–ä¸å¦ï¼Œå…¶â€œå…³çˆ±ä¼ é€’â€æ ¸å¿ƒå†…æ¶µå§‹ç»ˆæœªå˜ï¼Œå’Œç»“å©šä¸å¦æ›´æ— ç›´æ¥å…³è”ã€‚â€Œâ€Œ",
        "å¾·å›½æ€»ç†é»˜èŒ¨å½“å¤©åœ¨å‘è¨€ä¸­â€œå–Šè¯â€ç¾å›½ï¼šç¾å›½æ²¡æœ‰å®åŠ›ç‹¬è¡Œï¼Œæ¬§æ´²æ„è¯†åˆ°åº”å°½å¿«æ‘†è„±å¯¹ç¾è¿‡åº¦ä¾èµ–ã€‚é»˜èŒ¨è¡¨ç¤ºï¼Œå¾·å›½åšå®šæ”¯æŒè‡ªç”±è´¸æ˜“ã€æ°”å€™åå®šå’Œä¸–ç•Œå«ç”Ÿç»„ç»‡ç­‰ï¼Œâ€œåªæœ‰å›¢ç»“åä½œæ‰èƒ½åº”å¯¹å…¨çƒæ€§æŒ‘æˆ˜â€ã€‚â€Œâ€Œ",
        "ä¿„ä¹Œå†²çªåï¼Œå¾·å›½å¯¹åŒ—çº¦æ‰¿è¯ºçš„æ‹…å¿§åŠ å‰§ï¼Œå¯¼è‡´æ”¿æ²»å±‚é¢å¯¹ç¾ä¾èµ–åŠ æ·±ï¼Œä¸ç»æµåˆ©ç›Šå½¢æˆæ’•è£‚ã€‚â€Œâ€Œ",
        "è®©æˆ‘çœ‹çœ‹æ˜¯ä¸æ˜¯çœŸçš„æœ‰ç”¨"]
    print("\nğŸ”¥ Warming up & Compiling (Please wait)...")
    for i, warmup_text in enumerate(warmup_texts, 1):
        run_generation(model, warmup_text, "Chinese", voice_clone_prompt, label="warmup")
    print("âœ… System Ready.")

    # ============== Interactive Loop ==============
    print("\n" + "â€”" * 60)
    print("Interactive Mode Active. Type 'EXIT' to quit.")
    print("â€”" * 60)

    counter = 1
    while True:
        user_text = input(f"\n[{counter}] Input Chinese text: ").strip()
        
        if user_text.upper() == "EXIT":
            print("\nShutting down. Total uptime: {:.2f}s".format(time.time() - total_start))
            break
        
        if not user_text:
            continue

        # Run Generation
        res = run_generation(
            model, 
            user_text, 
            "Chinese", 
            voice_clone_prompt,
            label=f"user_input_{counter}"
        )

        # Save Audio
        filename = f"output_interactive_{counter}.wav"
        sf.write(filename, res["audio"], res["sample_rate"])

        # Display Performance
        print(f"âœ¨ Generated: {filename}")
        print(f"ğŸ“Š Performance: Latency: {res['total_time']:.3f}s | Audio: {res['audio_duration']:.2f}s | RTF: {res['rtf']:.4f}")
        
        counter += 1

if __name__ == "__main__":
    main()