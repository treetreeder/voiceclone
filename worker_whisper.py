from faster_whisper import WhisperModel
import time
import asyncio
import os
import io
import librosa
import boto3
import soundfile as sf
from dotenv import load_dotenv
from bullmq import Worker, Queue
import subprocess

load_dotenv()

# ============== R2 & Redis åˆå§‹åŒ– ==============
r2_client = boto3.client(
    's3',
    endpoint_url=os.getenv("R2_ENDPOINT"),
    aws_access_key_id=os.getenv("R2_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("R2_SECRET_ACCESS_KEY"),
)
redis_url = os.getenv("REDIS_URL")


# ==========================================
# è·å– GPU ä¿¡æ¯
# ==========================================
def get_gpu_model():
    """è‡ªåŠ¨æ£€æµ‹ GPU æ¨¡å‹"""
    try:
        output = subprocess.check_output(
            ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],
            text=True,
            timeout=5
        ).strip().split('\n')[0]
        return output
    except Exception as e:
        print(f"âš ï¸ GPU Detection Error: {e}") # This will print the exact reason it failed
        return os.getenv("WORKER_GPU", "unknown")

GPU_MODEL = get_gpu_model()
print(f"ğŸ›ï¸  Detected GPU: {GPU_MODEL}")


# åˆå§‹åŒ– TTS ä¸‹ä¸€é˜¶æ®µçš„é˜Ÿåˆ—
tts_queue = Queue("tts-queue", {"connection": redis_url})

# ==========================================
# æ­¥éª¤ 1ï¼šåŠ è½½ faster-whisper æ¨¡å‹
# ==========================================
print("ğŸ”„ Loading Whisper model...")
model = WhisperModel("large-v3", device="cuda", compute_type="float16")
print("âœ… Model loaded successfully\n")


async def process_transcribe_task(job, job_token):
    data = job.data
    print(f"\n[Whisper Worker] ğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡: {job.id}")
    
    voice_key = data['key']
    bucket = os.getenv("R2_BUCKET_NAME")
    
    try:
        # 1. ä¸‹è½½å‚è€ƒéŸ³é¢‘åˆ°å†…å­˜
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½éŸ³é¢‘åˆ°å†…å­˜: {voice_key}")
        audio_buffer = io.BytesIO()
        r2_client.download_fileobj(bucket, voice_key, audio_buffer)
        audio_buffer.seek(0)
        
        # 2. åŠ è½½åˆ° numpy æ•°ç»„
        audio_data, sample_rate = sf.read(audio_buffer)
        print(f"âœ… éŸ³é¢‘å·²åŠ è½½: {len(audio_data)} samples at {sample_rate}Hz")
        
        # Convert to mono if stereo
        if len(audio_data.shape) == 2:
            audio_data = audio_data.mean(axis=1)
            print(f"â„¹ï¸  è½¬æ¢ä¸ºå•å£°é“: {len(audio_data)} samples")
        
        # Convert to float32
        audio_data = audio_data.astype('float32')
        
        # ===== CRITICAL: Resample to 16kHz =====
        if sample_rate != 16000:
            print(f"ğŸ”„ Resampling {sample_rate}Hz â†’ 16kHz")
            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)
            sample_rate = 16000
            print(f"âœ… Resampled: {len(audio_data)} samples at {sample_rate}Hz")
        
        # ===== DEBUG INFO =====
        import numpy as np
        print(f"ğŸ” Audio stats:")
        print(f"   Min: {np.min(audio_data):.4f}, Max: {np.max(audio_data):.4f}")
        print(f"   Mean: {np.mean(audio_data):.4f}, Std: {np.std(audio_data):.4f}")
        
        # Normalize if too quiet
        max_val = np.max(np.abs(audio_data))
        if max_val < 0.1:
            print(f"âš ï¸  Audio is very quiet, normalizing...")
            audio_data = audio_data / (max_val + 1e-8) * 0.9
            print(f"   After norm - Max: {np.max(np.abs(audio_data)):.4f}")
        
        start_time = time.perf_counter()
        prompt = "è¿™æ˜¯ä¸€æ®µè¯­éŸ³è®°å½•ã€‚è¯·åŒ…å«æ ‡ç‚¹ç¬¦å·ï¼"

        # Transcribe WITHOUT initial_prompt first (it can confuse the model)
        segments, info = model.transcribe(
            audio_data,
    
            beam_size=5,
            initial_prompt="Please add punctuation. è¯·æ·»åŠ æ ‡ç‚¹ç¬¦å·ã€‚",
            condition_on_previous_text=False,
            vad_filter=False  # Disable VAD to test
        )

        full_text = ""
        for segment in segments:
            full_text += segment.text
        
        print(f"âœ… è½¬å½•æˆåŠŸ: {full_text if full_text else '(empty result)'}")
        print(f"ğŸ—£ï¸  æ£€æµ‹åˆ°è¯­è¨€: {info.language}")

        end_time = time.perf_counter()
        processing_time = end_time - start_time


        return {"transcript": full_text, "processingTime": round(processing_time, 2), "workerVersion": "whisper-v1", "workerGPU": GPU_MODEL}

    except Exception as e:
        print(f"âŒ Whisper ä»»åŠ¡ {job.id} å¤±è´¥: {str(e)}")
        raise e


async def main():
    queue_name = os.getenv("QUEUE_NAME", "transcribe-queue")
    print(f"\nğŸ¤– Whisper Worker æ­£åœ¨ç›‘å¬: {queue_name}...\n")
    
    worker = Worker(
        queue_name,
        process_transcribe_task,
        {"connection": redis_url, "concurrency": 1}
    )
    
    print("âœ… Worker is active and waiting for tasks...\n")
    
    try:
        await asyncio.Event().wait()
    except (asyncio.CancelledError, KeyboardInterrupt):
        print("\nğŸ›‘ Shutting down worker...")
    finally:
        await worker.close()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass