import asyncio
import os
import time
import io
import boto3
import soundfile as sf
from dotenv import load_dotenv
from bullmq import Worker
from processor import TTSProcessor
import subprocess

load_dotenv()

# ============== R2 & Redis åˆå§‹åŒ– ==============
r2_client = boto3.client(
    's3',
    endpoint_url=os.getenv("R2_ENDPOINT"),
    aws_access_key_id=os.getenv("R2_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("R2_SECRET_ACCESS_KEY"),
)
redis_url = os.getenv("REDIS_URL")
bucket = os.getenv("R2_BUCKET_NAME")
synthesis_prefix = os.getenv("R2_SYNTHESIS_PREFIX")

# åŠ è½½ TTS æ¨¡å‹ (åªåœ¨è¿™ä¸ªè¿›ç¨‹ä¸­åŠ è½½)
qwen = TTSProcessor()
qwen.load_model()

# ==========================================
# è·å– GPU ä¿¡æ¯
# ==========================================
def get_gpu_model():
    """è‡ªåŠ¨æ£€æµ‹ GPU æ¨¡å‹"""
    try:
        output = subprocess.check_output(
            ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],
            text=True,
            timeout=5
        ).strip().split('\n')[0]
        return output
    except Exception as e:
        print(f"âš ï¸ GPU Detection Error: {e}") # This will print the exact reason it failed
        return os.getenv("WORKER_GPU", "unknown")

GPU_MODEL = get_gpu_model()

async def process_tts_task(job, job_token):
    data = job.data
    print(f"\n[TTS Worker] ğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡: {job.id}")
    print(f"æ•°æ®: data={data}")
    
    voice_key = data['key']
    tts_text = data.get('tts', '')
    ref_text = data.get('transcript', '')
    tts_language = data.get('tts_language', 'auto')
    
    try:
        # 1. ä¸‹è½½å‚è€ƒéŸ³é¢‘åˆ°å†…å­˜
        
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å‚è€ƒéŸ³é¢‘: {voice_key}")
        
        audio_bytes = io.BytesIO()
        r2_client.download_fileobj(bucket, voice_key, audio_bytes)
        audio_bytes.seek(0)
        
        # 1. Load audio to memory (BytesIO)
        ref_audio_array, ref_sr = sf.read(audio_bytes, dtype='float32')

        # 2. Convert stereo to mono if needed
        if len(ref_audio_array.shape) > 1:
            ref_audio_array = ref_audio_array.mean(axis=1)
        
        start_time = time.perf_counter()
        
        # 3. Pass as tuple (exactly like warmup code)
        result = qwen.generate(
            ref_audio=(ref_audio_array, ref_sr),  # âœ… Tuple, not dict
            ref_text=ref_text,
            text=tts_text,
            language=tts_language,
        )
        
      # 4. ä¿å­˜è¾“å‡ºéŸ³é¢‘åˆ° R2
        output_filename = f"output_job_{job.id}.wav"
        
        # å†™å…¥éŸ³é¢‘åˆ°å†…å­˜ç¼“å†²åŒº
        audio_bytes = io.BytesIO()
        sf.write(audio_bytes, result["audio"], result["sample_rate"], format='WAV')
        file_size = audio_bytes.tell()  
        duration_seconds = len(result["audio"]) / result["sample_rate"]
        audio_bytes.seek(0)
        
        # ä¸Šä¼ åˆ° R2
        
        r2_key = f"{synthesis_prefix}/{output_filename}"
        r2_client.upload_fileobj(audio_bytes, bucket, r2_key)
        
        print(f"âœ¨ è¯­éŸ³ç”Ÿæˆå®Œæ¯•: {r2_key}")
        end_time = time.perf_counter()
        processing_time = end_time - start_time
        return {
            "key": r2_key,
            "duration": duration_seconds,
            "size": file_size,
             "processingTime": round(processing_time, 2), 
             "workerVersion": "qwen-v1",
              "workerGPU": GPU_MODEL
        }


    except Exception as e:
        print(f"âŒ TTS ä»»åŠ¡ {job.id} å¤±è´¥: {str(e)}")
        raise e

async def main():
    print(f"\nğŸ¤– TTS Worker æ­£åœ¨ç›‘å¬: clone-queue...")
    
    worker = Worker(
        "clone-queue",
        process_tts_task,
        {"connection": redis_url, "concurrency": 1}  # å¦‚æœæ˜¾å­˜å¤Ÿå¤§ï¼Œå¯ä»¥è°ƒé«˜å¹¶å‘
    )
    
    try:
        await asyncio.Event().wait()
    finally:
        await worker.close()

if __name__ == "__main__":
    asyncio.run(main())